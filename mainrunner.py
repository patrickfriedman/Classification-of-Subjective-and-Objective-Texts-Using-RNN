# -*- coding: utf-8 -*-
"""MainRunner.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17o3JOol-D4WPSvAS58Ld0I-hDylP17DD
"""

import numpy as np
import math
from keras.utils import to_categorical
from keras import models
from keras import layers


from google.colab import drive
drive.mount('/content/drive')

file1 = open("/content/drive/My Drive/JPEQ/finalObj.txt")
file2 = open("/content/drive/My Drive/JPEQ/finalSub.txt")

training_data = []
training_targets = []
testing_data = []
testing_targets = []
for line in file1:
  article1 = []
  for num in line.split(' '):
    if num.isnumeric():
      article1.append(int(num))
  training_data.append(article1)
  training_targets.append(0)
testing_data.append(training_data[0])
training_data = training_data[1:]

for line in file2:
  article2 = []
  for num in line.split(' '):
    if num.isnumeric():
      article2.append(int(num))
  training_data.append(article2)
  training_targets.append(1)
testing_data.append(training_data[0])
training_data = training_data[1:]

#(training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=10000)#edit training data and testing data, and targets


data = np.concatenate((training_data, testing_data), axis=0)
targets = np.concatenate((training_targets, testing_targets), axis=0)

def vectorize(sequences, dimension = 10000):
 results = np.zeros((len(sequences), dimension))
 for i, sequence in enumerate(sequences):
  results[i, sequence] = 1
 return results
 
data = vectorize(data)

targets = np.array(targets).astype("float32")
test_x = data[:80]
test_y = targets[:80]
train_x = data[80:]
train_y = targets[80:]
model = models.Sequential()
# Input - Layer
model.add(layers.Dense(50, activation = "relu", input_shape=(10000, )))
# Hidden - Layers
model.add(layers.Dropout(0.3, noise_shape=None, seed=None))
model.add(layers.Dense(50, activation = "relu"))
model.add(layers.Dropout(0.2, noise_shape=None, seed=None))
model.add(layers.Dense(50, activation = "relu"))
model.add(layers.Dropout(0.2, noise_shape=None, seed=None))
model.add(layers.Dense(50, activation = "relu"))
# Output- Layer
model.add(layers.Dense(1, activation = "sigmoid"))
model.summary()
# compiling the model
model.compile(
 optimizer = "adam",
 loss = "binary_crossentropy",
 metrics = ["accuracy"]
)
results = model.fit(
 train_x, train_y,
 epochs= 10,
 batch_size = 1,
 validation_data = (test_x, test_y)
)
print("Test-Accuracy:", np.mean(results.history["val_acc"]))

subOrObj=("Objective","Subjective")
newX = (322,44,2,876,121)
newX = vectorize(newX)
results = model.predict(newX)

print(subOrObj[int(max(results).round())], 'Confidence level: ' + str(100*max(results).round(4)))